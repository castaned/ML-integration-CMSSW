{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CMS Machine Learning Framework","text":"<p>This repository provides a framework for processing, training, and making inferences with machine learning models in the context of CMS experiments. The framework facilitates data preparation, model training, and evaluation to support ML-based analyses in high-energy physics.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>NanoAOD Filtering: Scripts for selecting relevant events and producing key physics variables.</li> <li>Data Preparation: Merging filtered NanoAOD samples and converting them into HDF5 format for efficient ML model training.</li> <li>Model Training &amp; Evaluation: Training machine learning models and performing performance tests to assess their effectiveness in anomaly detection or other tasks.</li> </ul>"},{"location":"#diagram","title":"Diagram","text":"<p>This diagram illustrates the tool's structure. The data processing section uses the CMSSW and GRID systems, but the training section does not.</p>"},{"location":"data_processing/01_set_config/","title":"Setting configuration","text":"<p>Before starting, you need to create the environment and clone the GitHub repository. If you already have all your data prepared, simply clone the repository and proceed to training section, where you will find two options: running the training in LXPLUS and outside LXPLUS.</p>"},{"location":"data_processing/01_set_config/#log-into-lxplus-server-cern-computers","title":"Log into LXPLUS server (CERN computers)","text":"<pre><code>ssh username@lxplus.cern.ch\n</code></pre>"},{"location":"data_processing/01_set_config/#set-up-the-required-cmssw-version","title":"Set up the required CMSSW version","text":"<pre><code>cmsrel CMSSW_13_3_0\ncmsenv\ncd CMSSW_13_3_0/src\n</code></pre> <p>You will see many of directories inside <code>CMSSW_13_3_0/</code>, but you only need to work inside <code>src/</code> directory.</p> <p>IMPORTANT</p> <ol> <li><code>cmsenv</code> needs to be executed every time you open a new terminal to activate the environment variables. You need to be inside <code>CMSSW_13_3_0/</code> directory.</li> <li>The Data processing section has been tested only with the CMSSW_13_3_0 release. The training section is not affected.</li> </ol>"},{"location":"data_processing/01_set_config/#clone-the-repository-and-compile","title":"Clone the repository and compile","text":"<pre><code>git clone https://github.com/castaned/ML-integration-CMSSW DeepNTuples\nscram b -j N\n</code></pre> <p>IMPORTANT</p> <p>Make sure not to change the name <code>DeepNTuples</code> for your local directory containing the GitHub repository, otherwise, it will not work.</p> <p>In the second command, <code>N</code> represents the CPUs to use for compiling and building the code inside <code>src/</code> directory, which uses dependencies from the CMSSW system. If you are unsure about <code>N</code>, simply run <code>scram b</code> without the <code>-j</code> flag, it will use all the available CPUs.</p> <p>Resources</p> <p>If you want to learn more about the CMSSW system, its structure, and commands, you can explore Intro to CMSSW and CMSSW SCRAM.</p>"},{"location":"data_processing/01_set_config/#set-up-grid-proxy-for-accessing-files","title":"Set up GRID proxy for accessing files","text":"<p>Ensure you have a valid GRID certificate. This is neccesary to have acces to the GRID, the distributed system used to retrieve the CERN data. If you don\u2019t have a GRID certificate, follow the instructions here. You need to generate the certificate and export it to the <code>~/.globus</code> directory in your LXPLUS user space, which is the standard location.</p> <p>This certificate cannot be used directly, you need to use a proxy. The proxy is a temporary credential derived from your certificate. Now, generate the proxy (it will ask your GRID passphrase)</p> <pre><code>voms-proxy-init --voms cms --valid 192:00 --out $HOME/.globus/x509up_u$(id -u)\n</code></pre> <p>This command created the proxy to be used with CMS data and sets its lifitime to 192 hours, if you do not specify this, it defaults to 12 hours, and 192 hours is the maximum allowed.</p> <p>We store the proxy inside our home directory because it is safer and easier to use when submitting jobs. If you do not specify the output, it is stored by default in the <code>/tmp/</code> directory. The <code>x509up_u$(id -u)</code> format is a naming convention that includes your user ID.</p> <p>Important</p> <p>When the time expires, you must execute the command again to renew the proxy.</p> <p>Now, verify that the certificate was correctly generated. First, we need to tell the system where our proxy is located, as mentioned earlier, the default directory is <code>/tmp/</code>, and the system will not find it if we saved it elsewhere. Therefore, we export the actual location</p> <pre><code>export X509_USER_PROXY=$HOME/.globus/x509up_u$(id -u)\n</code></pre> <p>The next command shows us the proxy information</p> <pre><code>voms-proxy-info --all\n</code></pre>"},{"location":"data_processing/01_set_config/#nanoaod-datasets-and-branch-selections","title":"NanoAOD datasets and branch selections","text":"<p>CERN has a complex data retrieval system composed of different softwares and data centers. In general, people from the experiments, e.g. CMS colaborators, produce data format releases that contain information recorded by the detectors or generated by Monte Carlo (MC) simulations. These releases can be in formats such as RECO, AOD, NanoAOD, etc. The format of interest for us is NanoAOD.</p> <p>These releases are datasets. Each dataset comes from an LHC run and contains different information about the recorded or simulated events. Multiples copies of these datasets exist across different data centers in the GRID. You can find more information about the nanoAOD releases in the GitLab project cms-nanoAOD.</p> <p>Info</p> <p>To access the gitlab repository, you must log in with your CERN account.</p> <p>To locate the datasets you need, you use the Data Aggregation System (DAS), it is a catalog that helps find the exact Logical File Names (LFNs) of the samples. DAS has its own query language, and the dataset paths follow a defined structure. You can find more information about DAS in Locating Data Samples.</p> <p>Once you identify the actual LFN of your desired samples, you use an entry point (or redirector) in XRootD to reach the endpoint, the nearest datacenter from your location that hosts the samples. The data is not downloaded; instead, it is read efficiently through the XRootD protocol and accessed directly from the LXPLUS cluster. For more details, see Using Xrootd Service (AAA) for Remote Data Access. </p> <p>To use the tool, you must create a text file with the following format</p> <p>Dataset path format file</p> <p>/Some/Das/query1/NANOAOD1.root:ID_1</p> <p>/Some/Das/query1/NANOAOD2.root:ID_1</p> <p>...</p> <p>/Some/Das/query2/NANOAOD1.root:ID_2</p> <p>/Some/Das/query2/NANOAOD2.root:ID_2</p> <p>...</p> <p>/Some/Das/queryn/NANOAODn.root:ID_n</p> <p>Esch ROOT file is associated with an ID. Root files from the same data release share the same ID. This ID will be the target variable in the model used to classify the physical phenomenon.</p> <p>Important</p> <p>The IDs need to be natural numbers.</p> <p>If you need help identifying your samples' FLN, refer again to Locating Data Samples. If you already know the sample FLN and want to use all root files in it, you can use the script <code>map_DASquery.py</code> as follow </p> <p><pre><code>map_DASquery.py /Some/Das/query/NANOAOD1 ... /Some/Das/query/NANOAOD2 datasets_FLN_filename.txt\n</code></pre> The file is located in <code>DeepNTuples/MyNanoAODTools</code> directory.</p>"},{"location":"data_processing/02_processing/","title":"Retrieve, skim, and convert data","text":""},{"location":"data_processing/02_processing/#step-4-update-necessary-configuration-files","title":"Step 4: Update necessary configuration files","text":"<ul> <li>Modify submit_condor.py</li> <li>change the proxy path  (from x509up_u29575 to x509up_u{id}\") where the {id} according to the user file</li> <li> <p>EOS user directory (e.g., /eos/user/u/username instead of /eos/user/c/castaned) according CERN username</p> </li> <li> <p>Modify run_filter.sh: </p> </li> <li> <p>work folder (e.g., replace /afs/cern.ch/work/c/castaned/CMSSW_13_3_0/src with your path, for instance /afs/cern.ch/user/u/username).</p> </li> <li> <p>EOS directory (e.g. replace EOS_DIR=\"/eos/user/c/castaned/NanoAOD_Filtered/${DATASET_FOLDER}\" with  EOS_DIR=\"/eos/user/u/username/NanoAOD_Filtered/${DATASET_FOLDER}\"</p> </li> <li> <p>create local directory for output</p> </li> </ul> <pre><code>mkdir filteredNanoAOD\n</code></pre> <ul> <li>Create directory in EOS to store output</li> </ul> <pre><code>mkdir /eos/user/u/username/NanoAOD_Filtered/\n</code></pre>"},{"location":"data_processing/02_processing/#step-5-submit-the-condor-jobs","title":"Step 5: Submit the Condor jobs","text":"<pre><code>python3 submit_condor.py\n</code></pre>"},{"location":"data_processing/02_processing/#step-6-monitor-job-progress","title":"Step 6: Monitor job progress","text":"<pre><code>condor_q\n</code></pre>"},{"location":"data_processing/02_processing/#step-7-verify-the-output","title":"Step 7: Verify the output","text":"<p>Once the jobs complete, check the EOS directory to confirm the skimmed samples were created successfully.</p> <p>After the jobs are finished a <code>json</code> file named <code>dataset_mapping.json</code> will be created with a mapping of all datasets to an integer number (this is used later to define labels in the training process)</p>"},{"location":"data_processing/02_processing/#step-8-create-txt-files-to-merge-sample","title":"Step 8: Create .txt files to merge sample","text":"<p>Back to the main directory </p> <pre><code>cd ../../\n</code></pre> <p>Use the <code>SamplesToMerge.sh</code> script to produce .txt in the corresponding EOS directory (change Path accordingly to your EOS area)</p> <pre><code># Set the directory containing the sample folders\nBASE_DIR=\"/eos/user/c/castaned/NanoAOD_Filtered\"\n</code></pre> <p>Execute the bash script</p> <pre><code>bash SamplesToMerge.sh\n</code></pre>"},{"location":"data_processing/02_processing/#step-9-merge-samples-randomly-optional","title":"Step 9: Merge samples randomly (optional)","text":"<p>See random sampling - optional section</p>"},{"location":"data_processing/02_processing/#step-10-produce-h5-files","title":"Step 10: Produce h5 files","text":"<p>Convert from .root to h5 (for all directories)</p> <p>Make sure all the variables are included in the <code>other_branches</code> list, if this is not the case udpate the list  if the list is updated the code need to be recompiled in <code>src</code> directory by the command <code>scram b -j8</code></p> <pre><code>emacs -nw Utilities/scripts/convert-uproot-opendata_v2.py\n</code></pre> <p>check that the script runs in one file</p> <pre><code>convert-uproot-opendata_v2.py $MERGEDIR/ntuple_merged_10.root $MERGEDIR/ntuple_merged_10.h5\n</code></pre> <p>Loop over complete dataset in the same MERGEDIR directory</p> <p><pre><code>bash convert_root_to_h5.sh\n</code></pre> which produces <code>HDF5</code> files.</p>"},{"location":"data_processing/03_random_sample_optional/","title":"Random sampling - Optional","text":"<ol> <li>Prepare your environment: Ensure you have access to a Condor-enabled system and your proxy is valid (<code>voms-proxy-init</code>).</li> <li>Prepare the list of random events: python3 create_indices.py   [ ...] <li>Modify paths and arguments:<ul> <li>In <code>submit_all.sh</code>, update <code>&lt;num_chunks&gt;</code> with the number of chunks you want to submit.</li> <li>Update the arguments in <code>mixSamples.jdl</code> and <code>submit_all.sh</code> to specify the <code>max_events</code>, <code>output_dir</code>, and the ROOT file lists (<code>txt_file1</code>, etc.).</li> </ul> </li> <li>Run the submission script: To submit the jobs, run:</li> <pre><code>bash submit_all.sh\n</code></pre>"},{"location":"datasets/01_nanoaod/","title":"NanoAOD Format","text":"<p>The NanoAOD (Nano Analysis Object Data) format is a lightweight and analysis-friendly data format used in the CMS Experiment at CERN. It is designed to provide a compact representation of event-level information, keeping only the most essential quantities for physics analyses.</p>"},{"location":"datasets/01_nanoaod/#structure-overview","title":"Structure Overview","text":"<p>NanoAOD files are ROOT files containing a single <code>Events</code> tree with branches for reconstructed and generator-level objects. Each branch stores arrays (or collections) of physics objects per event.</p> <p>Typical groups of branches include:</p> <ul> <li>Event information: run, luminosity block, event ID, generator weight, etc.  </li> <li>Physics objects:</li> <li>Electrons (<code>Electron_pt</code>, <code>Electron_eta</code>, <code>Electron_phi</code>, \u2026)</li> <li>Muons (<code>Muon_pt</code>, <code>Muon_eta</code>, <code>Muon_iso</code>, \u2026)</li> <li>Jets (<code>Jet_pt</code>, <code>Jet_btag</code>, <code>Jet_mass</code>, \u2026)</li> <li>Missing transverse energy (MET) (<code>MET_pt</code>, <code>MET_phi</code>)</li> <li>Trigger and filter information: HLT paths, event flags, etc.</li> </ul>"},{"location":"datasets/01_nanoaod/#documentation-versioning","title":"\ud83d\udcda Documentation &amp; Versioning","text":"<p>The NanoAOD format evolves with each CMSSW release, and the detailed documentation \u2014 including branch structure, schema definitions, and version notes \u2014 is maintained in the official repositories below.</p> <p>\u26a0\ufe0f Access Warning The CERN GitLab wiki requires CMS credentials (an active CERN account with CMS project access). If you are not logged in, you may see a 404 or \"Access Denied\" page.</p> <ul> <li> <p>Official NanoAOD Documentation Wiki (CERN GitLab)   Detailed versioning information, variable definitions, and schema updates:   \ud83d\udd17 https://gitlab.cern.ch/cms-nanoAOD/nanoaod-doc/-/wikis/home</p> </li> <li> <p>NanoAOD-tools on GitHub   Post-processing utilities, friend tree management, and helper scripts for analysis:   \ud83d\udd17 https://github.com/cms-nanoAOD/nanoAOD-tools</p> </li> <li> <p>NanoAOD definitions in CMSSW   Source code for NanoAOD production within the CMSSW framework:   \ud83d\udd17 https://github.com/cms-sw/cmssw/tree/master/PhysicsTools/NanoAOD</p> </li> </ul>"},{"location":"training/01_intro/","title":"Introduction to train model","text":"<p>To run it, modify the <code>set_config_variables.txt</code> file. Currently, the variables that can be modified are <code>train_path</code>, <code>test_path</code>, <code>output_path</code>, and <code>ideal_accuracy</code>. Follow the specified format in the <code>set_config_variables.txt</code> file to set the variables.</p>"},{"location":"training/01_intro/#repository-contents","title":"Repository Contents:","text":"<ul> <li>Main file (<code>main.py</code>)</li> <li>Model training (<code>src/optimize_model.py</code>)</li> <li>Evaluation and metrics (<code>src/test_results.py</code>)</li> <li>AI models (<code>models/models.py</code>)</li> <li>Configuration file reader (<code>read_config_variables.py</code>)</li> <li>Data formatting script (<code>prepare_data.py</code>)</li> <li>Required Python libraries (<code>requirements.txt</code>)</li> <li>Example output directory (<code>output/</code>)</li> <li>SLURM template (<code>acarus_template.slrm</code>)</li> <li>HTCondor template (<code>lxplus_template.sub</code>)</li> <li>Executable file for HTCondor (<code>apptainer_run_training.sh</code>)</li> <li>Apptainer container definition (<code>tool_container.def</code>)</li> </ul>"},{"location":"training/01_intro/#output-directory-content","title":"Output directory content:","text":"<ul> <li>MLflow experiments (<code>mlruns/</code>)</li> <li>Ray Tune optimization results (<code>tune_results/</code>)</li> <li>Weights and baises from the best models (<code>best_model_*.pth</code>)</li> <li>Standard output and error logs (<code>stdout.log</code> and <code>stderr.log</code>)</li> <li>Other results The outputs will be in the <code>output_path</code> directory.</li> </ul>"},{"location":"training/02_lxplus/","title":"Run tool in LXPLUS at CERN","text":""},{"location":"training/02_lxplus/#how-to-use","title":"How to Use","text":"<p>You need to set all the necessary configurations in the <code>set_config_variables.txt</code> file.</p>"},{"location":"training/02_lxplus/#1-create-an-environment","title":"1. Create an Environment","text":"<p>Ensure you have all the necessary dependencies within the <code>requirements.txt</code> file. When using HTCondor in LXPLUS to send a job, a sandbox  is created cointaining all transferred files. To streamline this, we recommend creating a containerized environment and submitting it. We can do it as follows:</p> <pre><code>apptainer build tool_container.sif tool_container.def\n</code></pre>"},{"location":"training/02_lxplus/#2-execute-the-project","title":"2. Execute the project","text":"<p>The standard error and output will be generated in the path specified in the <code>output_path</code> variable within <code>set_config_variables.txt</code>. To run the tool, we need to create a HTCondor file, <code>lxplus_template.sub</code> can be used as a template, just replace variable values with your information. If you are at another center that uses HTCondor, make the necessary modifications.</p> <pre><code>condor_submit lxplus_template.sub\n</code></pre> <p>The main file is <code>apptainer_run_training.sh</code>, which will run the code inside the container within the sandbox. The data to be used was prepared beforehand and stored as a tar file in the EOS system. In this main file, the data is descompressed for use.</p>"},{"location":"training/02_lxplus/#4-mlops","title":"4. MLOps","text":"<p>MLflow is used as the MLOps platform. To launch the UI, just execute the following command using the apptainer container created in step 1:</p> <pre><code>apptainer exec tool_container.sif mlflow ui --backend-store-uri output_path/mlruns/ --host IP_host --port some_port\n</code></pre> <p>Then, you can visualize it in your web browser by entering <code>IP_host:some_port</code>. However, in LXPLUS, it is not possible to visualize it directly, we need to create a tunnel to redirect the content to your local machine. To do so, execute the following command in your local machine's terminal:</p> <pre><code>ssh -N -L local_machine_port:IP_host:remote_machine_port user@lxplus.cern.ch -J user@remote_IP_where_mlflow_server_running\n</code></pre> <p>To get the <code>remote_IP_where_mlflow_server_running</code>, run the command:</p> <pre><code>hostname -I\n</code></pre> <p>The first IP is the server's IP where the MLflow server is running. The <code>remote_machine_port</code> and the <code>some_port</code> (from the MLflow command) must be the same, as well as the <code>IP_host</code>. Additionally, ensure the ports of both machines are available for use. The <code>-N</code> prevents execution of other command in the terminal that creates the tunnel, but it is not obligatory. Finally, enter the <code>IP_host:local_machine_port</code> in your web browser to access the MLflow platform.</p>"},{"location":"training/03_acarus/","title":"Run tool in a cluster at ACARUS","text":""},{"location":"training/03_acarus/#how-to-use","title":"How to Use","text":"<p>You need to set all the necessary configurations in the <code>set_config_variables.txt</code> file.</p>"},{"location":"training/03_acarus/#1-create-an-environment","title":"1. Create an Environment","text":"<p>Ensure you have all the necessary dependencies within the <code>requirements.txt</code> file. If you use the virtual environment venv, you can install them as follows:</p> <pre><code>python -m venv env_path\nsource env_path/bin/activate \npip install -r requirements.txt\n</code></pre>"},{"location":"training/03_acarus/#2-execute-the-project","title":"2. Execute the project","text":"<p>The standard error and output will be generated in the path specified in the <code>output_path</code> variable within <code>set_config_variables.txt</code>. Run the main scrpit:</p> <p><pre><code>python main.py -f set_config_variables.txt\n</code></pre> If you are running the tool on ACARUS (\u00c1rea de c\u00f3mputo de la Universidad de Sonora), submit the SLURM file. If you are at another center that uses SLURM, make the necessary modifications.</p> <pre><code>sbatch acarus_template.slrm\n</code></pre>"},{"location":"training/03_acarus/#3-mlops","title":"3. MLOps","text":"<p>MLflow is used as the MLOps platform. To launch the UI, make sure you are in the environment, then execute:</p> <p><pre><code>mlflow ui --backend-store-uri output_path/mlruns/ --host IP_host --port some_port\n</code></pre> Then, you can visualize it in your web browser by entering <code>IP_host:some_port</code>. Make sure the port is available. Tipically, <code>localhost</code> is used as <code>IP_host</code>. If you run the code in a computer that you enter through SSH, you need to create a tunnel to redirect the content to your local machine. To do so, execute the following command in your local machine' terminal:</p> <pre><code>ssh -N -L local_machine_port:IP_host:remote_machine_port user@remote_IP\n</code></pre> <p>The <code>remote_machine_port</code> and the <code>some_port</code> (from the MLflow command) must be the same, as well as the <code>IP_host</code>. Additionally, ensure the ports of both machines are available for use. The <code>-N</code> prevents execution of other command in the terminal that creates the tunnel, but it is not obligatory. Finally, as mentioned earlier, enter <code>IP_host:local_machine_port</code> in your web browser to access the MLflow plataform.</p>"}]}